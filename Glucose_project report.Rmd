---
title: "Glucose project"
author: "Van Nhut Ho"
date: "16/06/2020"
output:
  pdf_document: 
    fig_caption: yes
    fig_crop: no
    fig_height: 3
    fig_width: 4
    keep_tex: yes
    number_sections: yes
    toc: yes
  word_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

###################
#CAPSTONE PROJECT 2
###################

# Note: this process could take a couple of minutes
if(!require(foreign)) install.packages("foreign")
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(caret)) install.packages("caret")
if(!require(data.table)) install.packages("data.table")
if(!require(kableExtra)) install.packages("kableExtra")
if(!require(tidyr)) install.packages("tidyr")
if(!require(stringr)) install.packages("stringr")
if(!require(forcats)) install.packages("forcats")
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(timeDate)) install.packages("timeDate")
if(!require(corrplot)) install.packages("corrplot")
if(!require(mlr)) install.packages("mlr")

# All libraraies needed
library(foreign)
library(dplyr)
library(tidyverse)
library(kableExtra)
library(tidyr)
library(stringr)
library(forcats)
library(ggplot2)
library(timeDate)
library(corrplot)
library(mlr)
```

```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```

**Loading raw Data set**
```{r, include=FALSE, echo=FALSE}
glucose <- read.csv("C:/Users/vnh/Desktop/glc.csv")
```

\newpage


**1 EXECUTIVE SUMMARY**
The aim of this project is to show if the age and the weight influence on the glycemia (glucose). 
The Glycemia refers to the concentration of sugar or glucose in the blood. 
In many of the European countries blood glucose or sugar is also measured as millimol per decilitre (mmol/dl). 
These measurements are referred to as the SI units.
If the blood glucose level above 6.1 mmol/l or 1.10 g/l (hyperglycemia) and less than 3.5 mmol/l or 0.54 g/l (hypoglycemia)
When fasting blood glucose is above 7 mmol/l (1.26 g/l), the diagnosis of diabetes is made. 


**2 METHODS AND ANALYSIS**
**2.1 Data Analysis**
**2.1.1 Dataset exploration**
In this section, I'll present the methods and the analysis of the data. Before continuing the process, it's really important to discover the variables (names, types, counts, lenght etc.)

**Getting descriptive statistics**
This dataset contains 10 variables and 284 observations.

```{r, echo=FALSE, include=TRUE}
str(glucose)
```

**Type of variable :**
- id "integer" = unique identification value per patient
- chol "integer" = unique identification value of cholesterol per patient
- glyhb "numeric" = unique identification value of glycemia per patient
- location "factor" = specific city per patient
- age "integer" = age of patient
- gender "factor" = gender female or male
- height "numeric" = unique identification value per patient in cm
- weight "numeric" = unique identification value per patient in kg
- waist "integer" = unique identification value per patient in cm
- age_cat "factor" = age groups 20-39/40-59/60+ years


**checking for missing variables**
This data set has no missing vaule.

```{r, echo=FALSE, include=TRUE}
sapply(glucose, function(x) sum(is.na(x)))
```

**looking closer attributes and data values**
For all variables (except id, location, gender, age_cat because of nonsens), the mean and the median are close (= "egalitarian" distribution). We can see a large range for the variable chol and weight,.

```{r, echo=FALSE, include=TRUE}
summary(glucose)
```

**2.1.2 Univariate Plots Section**
One of the main goals of visualizing the data here is to observe which features are most helpful in predicting of type of glycemia (hyper-hypo glycemia).
Now we look closer the attributes and data values for:
**glyhb**
Mean-Median are close ("egalitarian" distribution)
Mean = 4.68
Median = 4.66
Skewness = 0.22 : asymmetry slightly to the right (-1 and +1) (+=to the right and 0=symmetry) coefficient of dyssimetry
Kurtosis = -0.3 : flat curve, symmetry relative concentration of observations because < 0 ,flattening coefficient <0=platycurtic; >0=leptocurtic distribution therefore sharper curve=lower flattening
Shape of the curve = Skewness+Kurtosis
Conclusion: almost symmetric

```{r, echo=FALSE, include=TRUE}
summary(glucose$glyhb)
skewness(glucose$glyhb)
kurtosis(glucose$glyhb)
```
Histogram
```{r, echo=FALSE, include=TRUE}
dfglyhb <- data.frame(glucose$glyhb)
ggplot(dfglyhb, aes(x = glucose$glyhb), binwidth = 2) + 
  geom_histogram(aes(y = ..density..), fill = 'red', alpha = 0.5) + 
  geom_density(colour = 'blue') + xlab(expression(bold('Glycemia'))) + 
  ylab(expression(bold('Density')))
```

Boxplot
Outlier : none
```{r, echo=FALSE, include=TRUE}
boxplot(glucose$glyhb)
```

**weight**
```{r, echo=FALSE, include=TRUE}
summary(glucose$weight)
skewness(glucose$weight)
kurtosis(glucose$weight)
```

Mean-Median are close ("egalitarian" distribution)
Mean = 77.47
Median = 77.01
Skewness = 0.32 : asymmetry slightly to the right (-1 and +1) (+=to the right and 0=symmetry) coefficient of dyssimetry
Kurtosis = -0.29 : flat curve, symmetry relative concentration of observations because < 0 ,flattening coefficient <0=platycurtic; >0=leptocurtic distribution therefore sharper curve=lower flattening
Shape of the curve = Skewness+Kurtosis
Conclusion: almost symmetric

Histogram
```{r, echo=FALSE, include=TRUE}
dfweight <- data.frame(glucose$weight)
ggplot(dfweight, aes(x = glucose$weight), binwidth = 2) + 
  geom_histogram(aes(y = ..density..), fill = 'blue', alpha = 0.5) + 
  geom_density(colour = 'blue') + xlab(expression(bold('Weight'))) + 
  ylab(expression(bold('Density')))
```



Boxplot
Outlier : none
```{r, echo=FALSE, include=TRUE}
boxplot(glucose$weight)
```

**age**
```{r, echo=FALSE, include=TRUE}
summary(glucose$age)
skewness(glucose$age)
kurtosis(glucose$age)
```

Mean-Median are close ("egalitarian" distribution)
Mean = 41
Median = 43.82
Skewness = 0.38 : asymmetry slightly to the right (-1 and +1) (+=to the right and 0=symmetry) coefficient of dyssimetry
Kurtosis = -0.71 : flat curve, symmetry relative concentration of observations because < 0 ,flattening coefficient <0=platycurtic; >0=leptocurtic distribution therefore sharper curve=lower flattening
Shape of the curve = Skewness+Kurtosis
Conclusion: almost symmetric

Histogram
```{r, echo=FALSE, include=TRUE}
dfage <- data.frame(glucose$age)
ggplot(dfage, aes(x = glucose$age), binwidth = 2) + 
  geom_histogram(aes(y = ..density..), fill = 'green', alpha = 0.5) + 
  geom_density(colour = 'blue') + xlab(expression(bold('age'))) + 
  ylab(expression(bold('Density')))
```
  
Boxplot
Outlier : none
```{r, echo=FALSE, include=TRUE}
boxplot(glucose$age)
```

**chol**

```{r, echo=FALSE, include=TRUE}
summary(glucose$chol)
skewness(glucose$chol)
kurtosis(glucose$chol)
```
Mean-Median are close ("egalitarian" distribution)
Mean = 199.0
Median = 200.5
Skewness = 0.23 : asymmetry slightly to the right (-1 and +1) (+=to the right and 0=symmetry) coefficient of dyssimetry
Kurtosis = 0.07 : weak flat curve, symmetry relative concentration of observations because = 0 ,flattening coefficient <0=platycurtic; >0=leptocurtic distribution therefore sharper curve=lower flattening
Shape of the curve = Skewness+Kurtosis
Conclusion: almost symmetric

Histogram
```{r, echo=FALSE, include=TRUE}
dfchol <- data.frame(glucose$chol)
ggplot(dfchol, aes(x = glucose$chol), binwidth = 2) + 
  geom_histogram(aes(y = ..density..), fill = 'black', alpha = 0.5) + 
  geom_density(colour = 'blue') + xlab(expression(bold('age'))) + 
  ylab(expression(bold('Density')))
```

Boxplot
Outlier : 1
Intlier : 1
```{r, echo=FALSE, include=TRUE}
boxplot(glucose$chol)
```


**2.1.3 Bivariate/Multivariate Analysis**
Correlation Plot with numeric variables:
We are now interested in how the 6 predictors relate to each other. 
To see bivariate relationships among these predictors, we calculate correlations between them. Correlations tell us:
 - whether this relationship is positive or negative
 - the strength of the relationship.

Value of r:	                Strength of relationship:
-1.0 to -0.5 or 1.0 to 0.5	Strong
-0.5 to -0.3 or 0.3 to 0.5	Moderate
-0.3 to -0.1 or 0.1 to 0.3	Weak
-0.1 to 0.1	                None or very weak

**Calculate collinearity**
Fellowing this corrplot, the variable glyhb has a bivariate relationships with the variable age, weight and waist. Note there is "no" relation between glyhb and height.

```{r, echo=FALSE, include=TRUE}
glucose1 <- glucose[ ,c("chol","glyhb","age", "height", "weight", "waist")]
glucose1
corrglucose <- cor(glucose1[,2:6])
corrplot(corrglucose, order = "hclust", tl.cex = 0.7)
```

**Linear regression**
Now let's have a quantitative score throught a scatter plots and calculation that can help visualize any linear relationships between the dependent (response) variable and independent (predictor) variables.

Linear regression between glycemia and weight:
Following this score and the scatter plot, there is a weak positive linear relationships between these variables.

```{r, echo=FALSE, include=TRUE}
cor(glucose$glyhb, glucose$weight, method = c("pearson", "kendall", "spearman"))
```

```{r, echo=FALSE, include=TRUE}
glycemia <- glucose$glyhb
weight <- glucose$weight
scatter.smooth(x=glycemia, y=weight, main="glycemia ~ kg")  # scatterplot
```

Linear regression between glycemia and cholesterol:
As we can see, there is a weak positive linear regression.

```{r, echo=FALSE, include=TRUE}
cor(glucose$glyhb, glucose$chol, method = c("pearson", "kendall", "spearman"))
```

```{r, echo=FALSE, include=TRUE}
glycemia <- glucose$glyhb
cholesterol <- glucose$chol
scatter.smooth(x=glycemia, y=cholesterol, main="glycemia ~ mmol/dl")  # scatterplot
```

Linear regression between glyemia and age:
Here we see a slight positive correlation between these variables.

```{r, echo=FALSE, include=TRUE}
cor(glucose$glyhb, glucose$age, method = c("pearson", "kendall", "spearman"))
```

```{r, echo=FALSE, include=TRUE}
glycemia <- glucose$glyhb
age <- glucose$age
scatter.smooth(x=glycemia, y=age, main="glycemia ~ age")  # scatterplot
```


Linear regression between glyemia and wast:
The score and the scatter plot show us a slight positive correlation between these variables.

```{r, echo=FALSE, include=TRUE}
cor(glucose$glyhb, glucose$waist, method = c("pearson", "kendall", "spearman"))
```

```{r, echo=FALSE, include=TRUE}
glycemia <- glucose$glyhb
scatter.smooth(x=glycemia, y=age, main="glycemia ~ waist")  # scatterplot
```


\newpage
**3 RESULTS***

**3.1 Principal Components Analysis (PCA) transform**
Principal component analysis is a statistical technique that is used to analyze the interrelationships among a large number of variables and to explain these variables in terms of a smaller number of variables (called principal components) with a minimum loss of information.
It constructs a set of orthogonal (non-collinear, uncorrelated, independent) variables and is used for making predictive models

This plot show us the increase of components(variables) the decrease of variances:

```{r echo=FALSE}
glucose.pca <- prcomp(glucose1, center=TRUE, scale=TRUE)
plot(glucose.pca, type="l", main='')
grid(nx = 6, ny = 5)
title(main = "Principal components weight", sub = NULL, xlab = "Components")
box()
```



```{r, echo=FALSE, include=TRUE}
summary(glucose.pca)
```
Following these results, the standard deviation of variables are low and indicate that the values tend to be close to the mean (also called the expected value) of the set.


**Proportion of variance explained**
To explain more than 0.95 of the variance, it's required 5 principal components and 5 for 0.99.

```{r, echo=FALSE, include=TRUE}
pca_var <- glucose.pca$sdev^2
pve_df <- pca_var / sum(pca_var)
cum_pve <- cumsum(pve_df)
pve_table <- tibble(comp = seq(1:ncol(glucose1)), pve_df, cum_pve)

ggplot(pve_table, aes(x = comp, y = cum_pve)) + 
  geom_point() + 
  geom_abline(intercept = 0.95, color = "red", slope = 0)
```

The features with highest dimmensions or aligned with the leading principal component are the ones with highest variance.
```{r, echo=FALSE, include=TRUE}
pca_df <- as.data.frame(glucose.pca$x)
ggplot(pca_df, aes(x=PC1, y=PC2, col=glucose$glyhb)) + geom_point(alpha=0.5)
```


**3.2 Machine learning**
 Machine learning algorithms build a mathematical model based on sample data (training data), in order to make predictions or decisions making without being explicitly programmed to do so.
**Split data into train and test sets**
The division of the dataset into two parts makes it possible to check the performance of the learning machine. I will Split the available data into a train set (65%) and a test set (35).

train_set = 187 rows
test_set = 97 rows

```{r, echo=FALSE, include=TRUE}
set.seed(2)
test_index <- createDataPartition(y = glucose$glyhb, p = 0.65, list = FALSE)
train_set <- glucose[test_index,]
test_set <- glucose[-test_index,]

nrow(train_set)
nrow(test_set)
```


**Overview train_set and test_set**

```{r, echo=FALSE, include=TRUE}
head(train_set) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                position = "center",
                font_size = 10,
                full_width = FALSE)
```

```{r, echo=FALSE, include=TRUE}
head(test_set) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                position = "center",
                font_size = 10,
                full_width = FALSE)
```

**3.2.1 Naive Bayes**
In machine learning, naïve Bayes classifiers are a family of simple "probabilistic classifiers" based on applying Bayes' theorem with strong independence assumptions between the features

Average of all glycemia
```{r, echo=FALSE, include=TRUE}
mu_hat <- mean(glucose$glyhb)
mu_hat
```

Predict the RMSE on the validation set
```{r, echo=FALSE, include=TRUE}
rmse_mean_model_result <- RMSE(test_set$glyhb, mu_hat)
```

Finally a dataframe of result
```{r, echo=FALSE, include=TRUE}
results <- data.frame(model="Naive Mean-Baseline Model", RMSE=rmse_mean_model_result)
results %>% 
   kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
             position = "center",
             font_size = 12,
             full_width = FALSE)
```

**3.2.2 Model building on training data to predict the glycemia on test data**
From the model summary, the model p value and predictor’s p value are less than the significance level = statistically significant model. 

**Calculate Akaike Information Criterion (AIC)**
The AIC is essentially an estimated measure of the quality of each of the available econometric models as they relate to one another for a certain set of data, making it an ideal method for model selection.

AIC between glyhb and weight:
```{r, echo=FALSE, include=TRUE}
lmMod <- lm(glyhb ~ weight, data=glucose)  # build the model
glyPred <- predict(lmMod, test_set)  # predict glycemia
summary (lmMod)  # model summary
```

```{r, echo=FALSE, include=TRUE}
lmMod2 <- lm(glyhb ~ age, data=glucose)  # build the model
glyPred2 <- predict(lmMod2, test_set)  # predict glycemia
summary (lmMod2)  # model summary
```

```{r, echo=FALSE, include=TRUE}
AIC(lmMod, lmMod2)
```

**Calculate Bayesian Information Criterion (BIC)**
The BIC is a variant of AIC with a stronger penalty for including additional variables to the model.
BIC between glyhb and weight:

```{r, echo=FALSE, include=TRUE}
BIC(lmMod, lmMod2)
```
AIC and BIC are small meaning that the econometric models is powerful.

**Average prediction error rate**
Dividing the RSE by the average value of the outcome variable will give us the prediction error rate, which should be as small as possible:
```{r, echo=FALSE, include=TRUE}
sigma(lmMod)/mean(glucose$glyhb)
```
The average prediction error rate is 12.7%.


**Calculate prediction accuracy and error rates**
A simple correlation between the actuals and predicted values can be used as a form of accuracy measure. 
A higher correlation accuracy implies that the actuals and predicted values have similar directional movement, i.e. when the actuals values increase the predicteds also increase and vice-versa.
```{r, echo=FALSE, include=TRUE}
actuals_preds <- data.frame(cbind(actuals=test_set$glyhb, predicteds=glyPred))  # make actuals_predicteds dataframe.
correlation_accuracy <- cor(actuals_preds)
head(actuals_preds)
```

**min_max_accuracy**
The result of min max accuracy is hight:
```{r, echo=FALSE, include=TRUE}
min_max_accuracy <- mean(apply(actuals_preds, 1, min) / apply(actuals_preds, 1, max))  
min_max_accuracy
```

**mean absolute percentage deviation**
The mean absolute percentage deviation is low:
```{r, echo=FALSE, include=TRUE}
map <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)
map
```


**3.2.3 Cross-validation methods**

**The Validation set Approach**
When comparing two models, the one that produces the lowest test sample RMSE is the preferred model.
Making predictions and computing the R2, RMSE and MAE:

```{r, echo=FALSE, include=TRUE}
model <- lm(glyhb ~., data = train_set)
predictions <- model %>% predict(test_set)
RMSE_K_FOLD_CROSS_VALIDATION <- RMSE(predictions, test_set$glyhb)
data.frame( R2 = R2(predictions, test_set$glyhb),
            RMSE = RMSE(predictions, test_set$glyhb),
            MAE = MAE(predictions, test_set$glyhb))
results <- results %>% add_row(model="K-fold cross-validation", RMSE=RMSE_K_FOLD_CROSS_VALIDATION)
```
The RMSE and the MAE are measured in the same scale as the outcome variable. Dividing the RMSE by the average value of the outcome variable will give us the prediction error rate, which should be as small as possible:

```{r, echo=FALSE, include=TRUE}  
RMSE(predictions, test_set$glyhb)/mean(test_set$glyhb)
```
Note that, the validation set method is only useful when you have a large data set that can be partitioned. 
Therefore, the test error rate can be highly variable, depending on which observations are included in the training set and which observations are included in the validation set.

**K-fold cross-validation**
The k-fold cross-validation method evaluates the model performance on different subset of the training data and then calculate the average prediction error rate. The algorithm is as follow:
- Randomly split the data set into k-subsets (or k-fold) (for example 5 or 10 subsets)
- Reserve one subset and train the model on all other subsets
- Test the model on the reserved subset and record the prediction error
- Repeat this process until each of the k subsets has served as the test set.
- Compute the average of the k recorded errors (cross-validation error) serving as the   performance metric for the model.
- K-fold cross-validation (CV) is a robust method for estimating the accuracy of a model.

Define training control and train the model
```{r, echo=FALSE, include=TRUE}
set.seed(200)
train.control <- trainControl(method = "cv", number = 10)
```

```{r, echo=FALSE, include=TRUE}
model <- train(glyhb ~., data = glucose, method = "lm",
               trControl = train.control)
```

Summarize the results
```{r, echo=FALSE, include=TRUE}
print(model)
```

**Repeated K-fold cross-validation**
The process of splitting the data into k-folds could be repeatedas many times as wished and called repeated k-fold cross validation.
The final model error is taken as the mean error from the number of repeats.

This following example uses 10-fold cross validation with 4 repeats:
Define training control and model
```{r, echo=FALSE, include=TRUE}
set.seed(200)
train.control2 <- trainControl(method = "repeatedcv", 
                              number = 10, repeats = 3)
model2 <- train(glyhb ~., data = glucose, method = "lm",
               trControl = train.control2)
```

Summarize the results
```{r, echo=FALSE, include=TRUE}
print(model2)
```

**Summarize RMSE table**
This table shows the RMSE results of models builted and trained. As we can see, applying K-fold cross-validation model reduce the RMSE score.

```{r, echo=FALSE, include=TRUE}  
results %>% 
   kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
             position = "center",
             font_size = 12,
             full_width = FALSE)
```



**Conclusion**
- The glycemia has a slight positive correlation with waist (0.17) and with age (0.30).
- The performant model metrics are powerfull (low AIC,BIC).
- The Naive Mean-Baseline Model	has a low RMSE (prediction errors) score.
- The K-fold Cross-Validation has a low RMSE score.

\newpage
```{r, echo=FALSE, include=TRUE}
sessionInfo()
```

